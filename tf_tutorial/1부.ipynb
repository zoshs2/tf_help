{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_learning = tf.constant('Deep Learning')\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Deep Learning'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(deep_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, name='x', shape=[None, 784])\n",
    "W = tf.Variable(tf.random_uniform([784,10], -1, 1), name='W')\n",
    "multiply = tf.matmul(x, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5> hello <br>\n",
    "it's **me**. </font><br>\n",
    "I'll be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복잡한 모델을 만들 때는 인스턴스화 하고 싶은 변수들의 집합을 한 곳에서부터 재사용하고 공유해야할 때가 많다.\n",
    "def my_network(input):\n",
    "    W_1 = tf.Variable(tf.random_uniform([784, 100], -1, 1), name='W_1')\n",
    "    b_1 = tf.Variable(tf.zeros([100]), name='biases_1')\n",
    "    output_1 = tf.matmul(input, W_1) + b_1 # z = (x * w) + b : Logit을 구하는 과정\n",
    "    \n",
    "    W_2 = tf.Variable(tf.random_uniform([100, 50], -1, 1), name='W_2')\n",
    "    b_2 = tf.Variable(tf.zeros([50]), name='biases_2')\n",
    "    output_2 = tf.matmul(output_1, W_2) + b_2\n",
    "    \n",
    "    W_3 = tf.Variable(tf.random_uniform([50, 10], -1, 1), name='W_3')\n",
    "    b_3 = tf.Variable(tf.zeros([10]), name='biases_3')\n",
    "    output_3 = tf.matmul(output_2, W_3) + b_3\n",
    "    \n",
    "    # 이름 출력\n",
    "    print(\"Printing names of weight parameters\")\n",
    "    print(f\"{W_1.name} {W_2.name} {W_3.name}\")\n",
    "    print(\"Printing names of bias parameters\")\n",
    "    print(f\"{b_1.name} {b_2.name} {b_3.name}\")\n",
    "    \n",
    "    return output_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그런데 두 개의 다른 입력으로 위 신경망을 사용하려고 시도하면...? 예상치못한 일이 발생한다.\n",
    "i_1 = tf.placeholder(tf.float32, [1000, 784], name='i_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing names of weight parameters\n",
      "W_1:0 W_2:0 W_3:0\n",
      "Printing names of bias parameters\n",
      "biases_1:0 biases_2:0 biases_3:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_2:0' shape=(1000, 10) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_network(i_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 입력 placeholder 인스턴스로 위 신경망을 다시 한 번 사용해보자.\n",
    "i_2 = tf.placeholder(tf.float32, [1000, 784], name='i_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing names of weight parameters\n",
      "W_1_1:0 W_2_1:0 W_3_1:0\n",
      "Printing names of bias parameters\n",
      "biases_1_1:0 biases_2_1:0 biases_3_1:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_5:0' shape=(1000, 10) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_network(i_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5> 오잉...? 이름이 이상해. 처음 사용했던 변수들과 이름이 달라? <br>\n",
    "즉, 서로 다른 입력인스턴스의 동일한 신경망 파라미터 변수를 사용하려고 할시, <br>\n",
    "사실상 동일한 변수를 사용하지 않는 것이다. <br>\n",
    "이름을 보아도 알겠지만, 서로 다르다! </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5> 이게 무슨 말이냐면, **입력할 때마다** 사본들을 계속 만들어내면서 <br>\n",
    "전혀 다른 변수집합들을 계속 만들어 사용한다는 것이다.<br>\n",
    "대부분의 경우에는 이처럼 파라미터 변수들이 매번 사본을 만들어 사용하는 것이 아니라,<br>\n",
    "동일한 변수들을 계속 재사용하길 원하는데(왜냐면 training을 해야하니까...), <br>\n",
    "**이 경우에는 tf.Variable을 사용해서는 안 된다**.<br>\n",
    "그 대신 **텐서플로의 변수 범위 지정**을 이용한 더욱 진보한 명명 체계를 사용해야한다.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(input, weight_shape, bias_shape):\n",
    "    weight_init = tf.random_uniform_initializer(minval=-1, maxval=1)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "    return tf.matmul(input, W) + b\n",
    "\n",
    "def my_network(input):\n",
    "    with tf.variable_scope(\"layer_1\"):\n",
    "        output_1 = layer(input, [784, 100], [100])\n",
    "\n",
    "    with tf.variable_scope(\"layer_2\"):\n",
    "        output_2 = layer(output_1, [100, 50], [50])\n",
    "    \n",
    "    with tf.variable_scope(\"layer_3\"):\n",
    "        output_3 = layer(output_2, [50, 10], [10])\n",
    "        \n",
    "    return output_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'layer_3/add:0' shape=(1000, 10) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_1 = tf.placeholder(tf.float32, [1000, 784], name='i_1')\n",
    "my_network(i_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/zoshs2/anaconda3/envs/tf_tutorial/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-443af6ca2414>\", line 2, in <module>\n",
      "    my_network(i_2)\n",
      "  File \"<ipython-input-22-aaada42b925f>\", line 10, in my_network\n",
      "    output_1 = layer(input, [784, 100], [100])\n",
      "  File \"<ipython-input-22-aaada42b925f>\", line 4, in layer\n",
      "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
      "  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 1572, in get_variable\n",
      "    aggregation=aggregation)\n",
      "  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 1315, in get_variable\n",
      "    aggregation=aggregation)\n",
      "  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 568, in get_variable\n",
      "    aggregation=aggregation)\n",
      "  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 520, in _true_getter\n",
      "    aggregation=aggregation)\n",
      "  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 869, in _get_single_variable\n",
      "    (err_msg, \"\".join(traceback.format_list(tb))))\n",
      "ValueError: Variable layer_1/W already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n",
      "\n",
      "  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 742, in _apply_op_helper\n",
      "    attrs=attr_protos, op_def=op_def)\n",
      "  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_state_ops.py\", line 1527, in variable_v2\n",
      "    shared_name=shared_name, name=name)\n",
      "  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/state_ops.py\", line 79, in variable_op_v2\n",
      "    shared_name=shared_name)\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zoshs2/anaconda3/envs/tf_tutorial/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zoshs2/anaconda3/envs/tf_tutorial/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/zoshs2/anaconda3/envs/tf_tutorial/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/zoshs2/anaconda3/envs/tf_tutorial/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/zoshs2/anaconda3/envs/tf_tutorial/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/zoshs2/anaconda3/envs/tf_tutorial/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/zoshs2/anaconda3/envs/tf_tutorial/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/zoshs2/anaconda3/envs/tf_tutorial/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/home/zoshs2/anaconda3/envs/tf_tutorial/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.keras'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable layer_1/W already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n    op_def=op_def)\n  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 742, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_state_ops.py\", line 1527, in variable_v2\n    shared_name=shared_name, name=name)\n  File \"/home/zoshs2/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/state_ops.py\", line 79, in variable_op_v2\n    shared_name=shared_name)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "i_2 = tf.placeholder(tf.float32, [1000, 784], name='i_2')\n",
    "my_network(i_2) # 에러 발생! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이처럼 tf.Variable 과는 달리 tf.get_variable 명령어는 주어진 이름의 변수가 인스턴스화 되지 않았는지를 확인해본다.\n",
    "# 기본적으로 이처럼 공유는 허용되지 않지만(안정성을 위해서), \n",
    "# 변수 범위 내에서 공유될 수 있게 하려면 다음과 같이 명시적으로 지정할 수 있다.\n",
    "with tf.variable_scope(\"shared_variables\") as scope:\n",
    "    i_1 = tf.placeholder(tf.float32, [1000, 784], name='i_1')\n",
    "    my_network(i_1)\n",
    "    scope.reuse_variables()\n",
    "    i_2 = tf.placeholder(tf.float32, [1000, 784], name='i_2')\n",
    "    my_network(i_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 CPU & GPU로 모델 관리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3> 계산 그래프가 어떤 장치들을 사용하는지 검사하기 위해<br>\n",
    "**log_device_placement=True**로 설정해 텐서플로 세션을 다음과 같이 초기화 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 7.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3> 여기 gate2 에서는 CPU, GPU커널이 모두 있는 상황이여서 <br>\n",
    "**/cpu:0** : 컴퓨터의 CPU<br>\n",
    "**/gpu:0** : 컴퓨터의 첫 번째 GPU<br>\n",
    "가 모두 조회된다. <br>\n",
    "그리고 GPU가 게다가 **사용가능한 상태**이므로, 텐서플로는 알아서 GPU사용을 자동으로 선택한다.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 (GPU or CPU)장치를 사용하고 싶다면, tf.device 로 적절한 장치를 선택할 수도 있다.\n",
    "# 하지만 선택한 장치가 사용불가능한 상태라면, 오류를 발생시킨다.\n",
    "# (Tip!) 선택한 장치가 '존재하지 않을 때'는 텐서플로에서 사용가능한 다른 장치를 알아서 찾아낼 수도 있다.\n",
    "# 이를 수행하기 위해서는 세션에 allow_soft_placement플래그를 True로 설정하면 된다.\n",
    "with tf.device('/device:GPU:2'): # GPU 1번 사용하기\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0], shape=[2, 2], name='a')\n",
    "    b = tf.constant([1.0, 2.0], shape=[2, 1], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 7.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.],\n",
       "       [11.]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3> 또한 텐서플로는 **\"타워 방식(Tower-like Fashion)\"**의 모델을 작성해서 <br>\n",
    "**여러 GPU를 사용하는 모델**을 만들 수 있다. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 7.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tower-like Fashion model\n",
    "c = []\n",
    "\n",
    "for d in ['/gpu:0', '/gpu:1']:\n",
    "    with tf.device(d):\n",
    "        a = tf.constant([1.0, 2.0, 3.0, 4.0], shape=[2, 2], name='a')\n",
    "        b = tf.constant([1.0, 2.0], shape=[2, 1], name='b')\n",
    "        c.append(tf.matmul(a, b))\n",
    "        \n",
    "with tf.device('/cpu:0'):\n",
    "    sum = tf.add_n(c)\n",
    "    \n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.],\n",
       "       [22.]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 우선 여기서 마무리하고 다음 노트(ipynb)에서 GPU를 어떻게하면 똑똑하게 사용하는지 알아보도록 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
